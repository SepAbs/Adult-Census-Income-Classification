{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Abbaspour - 610398147 - HW2\n",
    "Here we want to measure four classifiers for adult income dataset.\n",
    "First we import some methods from some libraries such as Numpy, Pandas, Sklearn, Skopt (contains optimizer methods of Sklearn library)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from numpy import array, logspace, NaN\n",
    "from pandas import concat, get_dummies, read_csv, set_option\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.metrics import accuracy_score, classification_report, ConfusionMatrixDisplay, f1_score, precision_recall_curve, precision_score, recall_score, roc_curve, roc_auc_score\n",
    "from sklearn.model_selection import StratifiedKFold, train_test_split\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.utils import resample\n",
    "from skopt import BayesSearchCV\n",
    "from skopt.space.space import Categorical, Integer \n",
    "from time import time\n",
    "from matplotlib.pyplot import bar, box, figure, legend, plot, savefig, scatter, show, subplot, subplots, title, xlabel, ylabel\n",
    "from warnings import filterwarnings\n",
    "# Code for filtering out the warning.\n",
    "filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we allocate some memmory for data frame extracted from dataset and a dictionary has classifiers names and their raw structure for tuning parameters by means of Baysesian Search Optimization appoach."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Defining whatever is needed.\n",
    "df, Scales, Standardizer, PCA, CV = read_csv(\"Adult.csv\", names = [\"age\", \"workclass\", \"fnlwgt\", \"education\", \"education-num\", \"marital-status\", \"occupation\", \"relationship\", \"race\", \"sex\", \"capital-gain\", \"capital-loss\", \"hours-per-week\", \"native-country\", \"income\"], header = None, index_col = None, delimiter = \" *, *\").copy(), {\"age\": \"Standardization\", \"workclass\": \"One-hot\", \"education-num\": \"Standardization\", \"marital-status\": \"One-hot\", \"occupation\": \"One-hot\", \"relationship\": \"One-hot\", \"race\": \"One-hot\", \"sex\": \"One-hot\", \"hours-per-week\": \"Standardization\", \"native-country\": \"One-hot\", \"income\": \"One-hot\"}, StandardScaler(), PCA(n_components = 20), StratifiedKFold(n_splits = 5, shuffle = True, random_state = 682)\n",
    "# Classifiers with their raw model structure for being fine-tuned.\"\n",
    "# Dictionary of Classifiers = {Known name of classifier: (Classifier(), BayesSearchCV(Target Parameters & ...))}\n",
    "# 'linear' and 'poly' kernels  won't be checked for tuning SVM classification model because of magnitude of dataset.\n",
    "Classifiers, ROCAUC, PCA_ROCAUC = {\"SVM\": (SVC, BayesSearchCV(estimator = SVC(), search_spaces = {\"C\": [0.1, 1, 10, 100], \"gamma\": [1, 0.1, 0.01], \"kernel\": [\"rbf\", \"sigmoid\"], \"probability\": [True]}, n_iter = 20, cv = CV)), \"Naive Bayes\": (GaussianNB, BayesSearchCV(estimator = GaussianNB(), search_spaces = {'priors': [None], \"var_smoothing\": logspace(0, -9, num = 100)}, scoring = \"accuracy\", cv = CV, n_jobs = 1, n_iter = 28, refit = False, random_state = 682)), \"KNN\": (KNeighborsClassifier, BayesSearchCV(estimator = KNeighborsClassifier(), search_spaces = {\"algorithm\": [\"auto\", \"ball_tree\", \"kd_tree\", \"brute\"], \"n_neighbors\": Integer(2, 40), 'p': Integer(1, 2), \"weights\": Categorical([\"distance\", \"uniform\"])}, scoring = \"accuracy\", cv = CV, n_jobs = 1, n_iter = 28, refit = False, random_state = 682)), \"MLP\": (MLPClassifier, BayesSearchCV(estimator = MLPClassifier(), search_spaces = {\"activation\": [\"identity\", \"logistic\", \"relu\", \"tanh\"], \"alpha\": [0.0001, 0.05], \"early_stopping\": [False], \"learning_rate\": [\"adaptive\", \"constant\", 'invscaling'], \"max_iter\": [100], \"solver\": [\"adam\", \"sgd\"], \"warm_start\": [False]}, scoring = \"accuracy\", cv = CV, n_jobs = 1, n_iter = 28, refit = False, random_state = 682))}, [], []"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here's the main and only function defined in the code.\n",
    "This function gets each classifier as input, applies PCA transformation if parameter 'bPCA' has \"True\" value.\n",
    "Then it uses validation set to fine tune the classifier by means of it's corresponding mentioned raw model.\n",
    "After the model gets ready with it's optimal or semi-optimal parameters, it becomes trained by trainset.\n",
    "After that, it becomes evaluated by metrics mentioned in HW2 documentary.\n",
    "Tuning SVM took a much long time so I decided to remain it with some default and well-known parameters, exceptionally."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# All classifiers uses the same pattern for being tuned, trained and tested.\n",
    "def Main(Classifier, bPCA = False):\n",
    "    print(f\"\\n{Classifier} Modeling Started!\")\n",
    "    # Using Bayes Search approach for tuning model\n",
    "    # Checking whether PCA approach is implied or not. \n",
    "    if bPCA:\n",
    "        print(\"PCA transformation implied!\")\n",
    "        X_tr, X_v, X_tt = PCAX_train, PCAX_val, PCAX_test\n",
    "    else:\n",
    "        X_tr, X_v, X_tt = X_train, X_val, X_test\n",
    "\n",
    "    CLF = Classifiers[Classifier]\n",
    "    Model = CLF[1]\n",
    "    startTime = time()\n",
    "    # Obtaining best paramteres by using splitted validation data\n",
    "    Model.fit(X_v, y_val)\n",
    "    Duration = time() - startTime # Calculating how long fitting validation data takes\n",
    "    print(f\"\\nModel's best score is:\\n{Model.best_score_}\\n\\nModel's best parameters are:\\n{Model.best_params_}\")\n",
    "    Model = CLF[0](**Model.best_params_) # = CLF[0](Optimal Parameters)\n",
    "    print(f\"\\n{Model}\")\n",
    "    # Evaluation Time!\n",
    "    Model.fit(X_tr, y_train)\n",
    "    y_pred, y_pred_proba = Model.predict(X_tt), Model.predict_proba(X_tt)[:,1]\n",
    "    if bPCA:\n",
    "        PCA_ROCAUC.append(y_pred_proba)\n",
    "    else:\n",
    "        ROCAUC.append(y_pred_proba)\n",
    "    print(f\"\\nModel Score: {Model.score(X_tt, y_pred)}\\n\\nAccuracy Score: {accuracy_score(y_test, y_pred)}\\n\\nPrecision Score: {precision_score(y_test, y_pred)}\\n\\nRecall Score: {recall_score(y_test, y_pred)}\\n\\nROC AUC Score: {roc_auc_score(y_test, y_pred_proba)}\\n\\nF1-Score: {f1_score(y_test,y_pred)}\\n\\nComputation Time: {Duration} UTC\")\n",
    "\n",
    "    # Comprehensive classification report.\n",
    "    print(f\"\\nClassification Report:\\n{classification_report(y_test, y_pred)}\")\n",
    "    ConfusionMatrixDisplay(confusion_matrix = confusion_matrix(y_test, y_pred), display_labels = [\"Positive\", \"Negative\"]).plot()\n",
    "\n",
    "    # Plotting Precision-Recall Curve\n",
    "    Precision, Recall, Threshold = precision_recall_curve(y_test, y_pred_proba)\n",
    "    fig, ax = subplots(figsize = (6,6))\n",
    "    ax.plot(Recall, Precision, label = f\"{Classifier} Classification\", color = \"firebrick\")\n",
    "    ax.set_title(\"Precision-Recall Curve\")\n",
    "    ax.set_xlabel(\"Recall\")\n",
    "    ax.set_ylabel(\"Precision\")\n",
    "    box(False)\n",
    "    ax.legend()\n",
    "    show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Preprocessing dataset\n",
    "Dataset was so messy had many missing values and was inbalanced as there was many samples with income which needed to be resampled (down sampling)\n",
    "Features \"fnlwgt\", \"education\", \"capital-gain\" and \"capital-loss\" didn't do important roles in classifying and were candidate to be dropped.\n",
    "Categorical features (StandardScaler) and binary features (One-hot) encoded by 'Scales' dictionary defined above.\n",
    "Missing values got filled with mod of values their related feature"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Showing all the columns in the table.\n",
    "set_option(\"display.max_columns\", None)\n",
    "print(df.head())\n",
    "print()\n",
    "print(df.shape)\n",
    "print()\n",
    "\n",
    "# from above data we can say that education and flnwgt is not required to predict the income.\n",
    "# education has one more representation in data by the variable \"education_num\"\n",
    "# thus education can be removed.\n",
    "# Features 'capital_gain' and 'capital_loss' are also useless.\n",
    "df = df.drop([\"fnlwgt\", \"education\", \"capital-gain\", \"capital-loss\"], axis = 1)\n",
    "print(df.head())\n",
    "\n",
    "Features = df.columns\n",
    "for Feature in Features:\n",
    "    print(df[Feature].unique())\n",
    "\n",
    "# missing values are in \"?\" form \n",
    "# thus we need to replace \"?\" with \"NAN\"\n",
    "df = df.replace([\"?\"], NaN)\n",
    "df.isnull().sum()\n",
    "\n",
    "# Thus from above we can see that dataset has missing values.\n",
    "# Now we have to replace these missing values with measure of central tendancy\n",
    "# in this case we have to replace them with modes of the respective veriables.\n",
    "for Feature in [\"workclass\", \"occupation\", \"native-country\"]:\n",
    "    df[Feature].fillna(df[Feature].mode()[0], inplace = True)\n",
    "print(df.isnull().sum())\n",
    "\n",
    "# Balancing data\n",
    "print(df[\"income\"].value_counts())\n",
    "# Downsampling records with incomes '<= 50k'\n",
    "df = concat([resample(df[df[\"income\"] == \"<=50K\"], replace = False, n_samples = 11687, random_state = 123), df[df[\"income\"] == \">50K\"]])\n",
    "# Perfectly Balanced!\n",
    "print(df[\"income\"].value_counts())\n",
    "\n",
    "# Preprocessing data records!\n",
    "for Feature in Features:\n",
    "    if Scales[Feature] == \"Standardization\":\n",
    "        df[Feature] = Standardizer.fit_transform(array(df[Feature]).reshape(-1, 1))\n",
    "    else:\n",
    "        df = concat([df, get_dummies(df[[Feature]], dtype = int)], axis = 1).drop([Feature], axis = 1)\n",
    "#income: 0 --> <=50k & 1 --> >50k\n",
    "df.rename(columns = {\"income_>50K\": \"income\"}, inplace = True)\n",
    "df = df.drop([\"income_<=50K\"], axis = 1)\n",
    "# Thus from above we can see that we have removed all the missing values.\n",
    "print(df.info())\n",
    "print(df.describe)\n",
    "\n",
    "# Plotting encoded values of features\n",
    "Features = df.columns.values\n",
    "for Feature in Features:\n",
    "  print(Feature)\n",
    "  df[Feature].hist()\n",
    "  show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Splitting Dataset and PCA Transformation\n",
    "We splitted dataset into trainset, validation set and testset and standardized the once more for make them be ready to be in PCA form.\n",
    "PCA affects are also plotted and feature of preprocessed dataset from 85 features to 20 main features."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating X & Y and splitting the data into training and testing data set.\n",
    "X, y = df.drop([\"income\"], axis = 1), df[\"income\"]\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.3, random_state = 42) # 70:30\n",
    "# 'test_size=0.5' split into 50% and 50%. The original data set is 30%; so, it will split into 15% equally.\n",
    "X_val, X_test, y_val, y_test = train_test_split(X_test, y_test, test_size = 0.5, random_state = 42) # 70:15:15\n",
    "print(f\"Training X shape: {X_train.shape}\\nTraining Y shape: {y_train.shape}\\nValidation X shape: {X_val.shape}\\nValidation Y shape: {y_val.shape}\\nTest X shape: {X_test.shape}\\nTest Y shape: {y_test.shape}\")\n",
    "# Standardization once more!\n",
    "X, X_train, X_val, X_test = Standardizer.fit_transform(X), Standardizer.fit_transform(X_train), Standardizer.fit_transform(X_val), Standardizer.transform(X_test)\n",
    "#Applying the PCA. (For Feature Selection)\n",
    "PCAX, PCAX_train, PCAX_val, PCAX_test = PCA.fit(X), PCA.fit_transform(X_train), PCA.transform(X_val), PCA.transform(X_test)\n",
    "\n",
    "# Barplotting effect of PCA transformation (by variance)\n",
    "figure(figsize = (25,7)) \n",
    "subplot(1, 2, 1)\n",
    "xlabel(\"PCA Feature\")\n",
    "ylabel(\"Variance\")\n",
    "title(\"PCA for Data Set\")\n",
    "bar(range(0, PCAX.explained_variance_ratio_.size), PCAX.explained_variance_ratio_)\n",
    "show()\n",
    "print(f\"Explained variance ratio is:\\n{PCA.explained_variance_ratio_}\\n\\n{PCA.n_components_}\\n\\nFeature vector of train set after applying PCA feature reduction method:\\n{PCAX_train}\\n\\nFeature vector of test set after applying PCA feature reduction method:\\n{PCAX_test}\")\n",
    "\n",
    "# Formatting\n",
    "Colors, Targets, lw, Alpha = [\"navy\", \"darkorange\"], [0, 1], 2, 0.3\n",
    "# 2 Components PCA\n",
    "figure(2, figsize = (20, 8))\n",
    "subplot(1, 2, 1)\n",
    "PCAX = PCAX.transform(X)\n",
    "for Color, i, Target in zip(Colors, [0, 1], Targets):\n",
    "    scatter(PCAX[y == i, 0], PCAX[y == i, 1], color = Color, alpha = Alpha, lw = lw, label = Target)\n",
    "legend(loc = \"best\", shadow = False, scatterpoints = 1)\n",
    "title(\"First Two PCA Directions\")\n",
    "show()\n",
    "# 3 Components PCA\n",
    "ax = subplot(1, 2, 2, projection = \"3d\")\n",
    "for Color, i, Target in zip(Colors, [0, 1], Targets):\n",
    "    ax.scatter(PCAX[y == i, 0], PCAX[y == i, 1], PCAX[y == i, 2], color = Color, alpha = Alpha, lw = lw, label = Target)\n",
    "legend(loc = \"best\", shadow = False, scatterpoints = 1)\n",
    "ax.set_title(\"First Three PCA Directions\")\n",
    "ax.set_xlabel(\"1st Eigenvector\")\n",
    "ax.set_ylabel(\"2nd Eigenvector\")\n",
    "ax.set_zlabel(\"3rd Eigenvector\")\n",
    "# rotate the axes\n",
    "ax.view_init(30, 10)\n",
    "show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Main & ROC Curves Visualization\n",
    "Here's to use each classifier and evaluate them and then plot a ROC curve for all classifiers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# main()\n",
    "for Classifier in Classifiers:\n",
    "    Main(Classifier)\n",
    "    Main(Classifier, True)\n",
    "    \n",
    "# Plotting ROC curves for all classifiers.\n",
    "print(\"\\nPlotting ROC curves for all classifiers without considering PCA transformations.\")\n",
    "# roc curve for tpr = fpr\n",
    "FPR, TPR, _ = roc_curve(y_test, [0 for i in range(len(y_test))], pos_label = 1)\n",
    "SVM_FPR, SVM_TPR, SVM_Threshold = roc_curve(y_test, ROCAUC[0], pos_label = 1)\n",
    "NB_FPR, NB_TPR, NB_Threshold = roc_curve(y_test, PCA_ROCAUC[1], pos_label = 1)\n",
    "KNN_FPR, KNN_TPR, KNN_Threshold = roc_curve(y_test, PCA_ROCAUC[2], pos_label = 1)\n",
    "MLP_FPR, MLP_TPR, MLP_Threshold = roc_curve(y_test, PCA_ROCAUC[3], pos_label = 1)\n",
    "plot(SVM_FPR, SVM_TPR, linestyle = \"--\", color = \"black\", label = \"SVM\")\n",
    "plot(NB_FPR, NB_TPR, linestyle = \"--\", color = \"orange\", label = \"Naive Bayes\")\n",
    "plot(KNN_FPR, KNN_TPR, linestyle = \"--\", color = \"green\", label = \"KNN\")\n",
    "plot(MLP_FPR, MLP_TPR, linestyle = \"--\", color = \"blue\", label = \"MLP\")\n",
    "plot(FPR, TPR, linestyle = \"--\", color = \"red\")\n",
    "# title\n",
    "title(\"ROC Curve\")\n",
    "# x label\n",
    "xlabel(\"False Positive Rate\")\n",
    "# y label\n",
    "ylabel(\"True Positive Rate\")\n",
    "legend(loc = \"best\")\n",
    "savefig(\"ROC\", dpi = 1200)\n",
    "show()\n",
    "\n",
    "print(\"\\nPlotting ROC curves for all classifiers considering PCA transformations.\")\n",
    "PCA_SVM_FPR, PCA_SVM_TPR, PCA_SVM_Threshold = roc_curve(y_test, PCA_ROCAUC[0], pos_label = 1)\n",
    "PCA_NB_FPR, PCA_NB_TPR, PCA_NB_Threshold = roc_curve(y_test, PCA_ROCAUC[1], pos_label = 1)\n",
    "PCA_KNN_FPR, PCA_KNN_TPR, PCA_KNN_Threshold = roc_curve(y_test, PCA_ROCAUC[2], pos_label = 1)\n",
    "PCA_MLP_FPR, PCA_MLP_TPR, PCA_MLP_Threshold = roc_curve(y_test, PCA_ROCAUC[3], pos_label = 1)\n",
    "plot(PCA_SVM_FPR, PCA_SVM_TPR, linestyle = \"--\", color = \"black\", label = \"SVM\")\n",
    "plot(PCA_NB_FPR, PCA_NB_TPR, linestyle = \"--\", color = \"orange\", label = \"Naive Bayes\")\n",
    "plot(PCA_KNN_FPR, PCA_KNN_TPR, linestyle = \"--\", color = \"green\", label = \"KNN\")\n",
    "plot(PCA_MLP_FPR, PCA_MLP_TPR, linestyle = \"--\", color = \"blue\", label = \"MLP\")\n",
    "plot(FPR, TPR, linestyle = \"--\", color = \"red\")\n",
    "# title\n",
    "title(\"ROC Curve by PCA\")\n",
    "# x label\n",
    "xlabel(\"False Positive Rate\")\n",
    "# y label\n",
    "ylabel(\"True Positive Rate\")\n",
    "legend(loc = \"best\")\n",
    "savefig(\"ROC\", dpi = 1200)\n",
    "show()\n",
    "\n",
    "print(\"THE-END!!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Evaluation\n",
    "According to numerical scores, matrix and precision-recall curve for each classifier, we have the following results:\n",
    " According to scores and visualizations:\n",
    " Naive Bayes classification did worst between them.\n",
    " Naive Bayes classified better when PCA implement but SVM, KNN and MLP did it worse than not using it.\n",
    " Afer all, training with all classifiers was faster when using PCA transformation.\n",
    " According to ROC curves (in 'Evaluation' folder also contains confusion matrices and precision-recall curves!) MLP approximately does the best unless using PCA transformation, and KNN does the best when using that.\n",
    " SVM and KNN clasisifiers did their bests close to perfomance of MLP classifier.\n",
    " In 'Evaluation' folder, we have precision-recall curve, confusion matrix and numerical scores for each classifier not considering and considering PCA transformation, respectively."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
